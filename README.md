# Final-Year-Project

Mobile robots depends on a reliable and effective navigation system. This presents a method for mobile robot navigation that combines sensors, algorithms, and control schemes to produce precise and dependable navigation performance. The effectiveness of the approach is demonstrated through simulation and experimental results, highlighting its potential for real-world applications. Mobile robot localization and navigation are difficult tasks that call for precise and dependable sensing and perception abilities. In robotics, an approach called optical flow is frequently used to infer the motion of objects in the environment from a series of images. Robots are now able to estimate their position and velocity in real-time thanks to optical flow-based approaches for mobile robot localization and navigation that have produced promising results. However, the accuracy and robustness of conventional optical flow-based approaches are constrained by noise and uncertainty.

The proposed system makes use of a monocular camera that is mounted on the robot to calculate the robot's current velocity by examining the optical flow obtained from a series of pictures that were taken by the camera. A deep neural network is fed the optical flow, and it extracts pertinent features and calculates the robot's current velocity. An optical flow-based perception module and a deep neural network-based control module are both parts of the proposed system's architecture.

Experimental findings show that the suggested strategy works well in a variety of situations, including both indoor and outdoor settings. The system achieves high robustness and accuracy in localizing mobile robots, making it a promising option for practical applications. Robots could localize in a variety of environments with the help of the integration of optical flow and deep learning, which has the potential to increase the precision and resiliency of mobile robot localization and navigation.
